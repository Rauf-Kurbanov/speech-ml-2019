{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaldi.feat.mfcc import Mfcc, MfccOptions\n",
    "from kaldi.matrix import SubVector, SubMatrix\n",
    "from kaldi.util.options import ParseOptions\n",
    "from kaldi.util.table import SequentialWaveReader\n",
    "from kaldi.util.table import MatrixWriter\n",
    "from numpy import mean\n",
    "from sklearn.preprocessing import scale, MinMaxScaler\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv1D, Conv2D, Reshape, MaxPooling1D, Flatten, UpSampling1D\n",
    "from keras.layers import TimeDistributed, RepeatVector\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "scaler = MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "current_time = start_time\n",
    "def log(message):\n",
    "    global current_time\n",
    "    t = time()\n",
    "    print(f\"{message}, {int(t - current_time)}s, total {int(t - start_time)}s\")\n",
    "    current_time = t\n",
    "def start():\n",
    "    global start_time\n",
    "    global current_time\n",
    "    start_time = time()\n",
    "    current_time = start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavs_dir = \"/home/larkkin/data/VCTK-Corpus/wav48/\"\n",
    "dirs = os.listdir(wavs_dir)\n",
    "files = []\n",
    "for d in dirs:\n",
    "    dir_files = os.listdir(os.path.join(wavs_dir, d))\n",
    "    files.extend([os.path.join(wavs_dir, d, f) for f in dir_files if not f.startswith(\"noise\") and\\\n",
    "                                                                     not f.endswith(\"raw\")])\n",
    "with open(\"testfile.scp\", \"w\") as otp:\n",
    "#     otp.write('\\n'.join([f\"{filename} {os.path.join(wavs_dir, filename)}\" for filename in files]))\n",
    "    otp.write('\\n'.join([f\"{filename.split('/')[-1]} {filename}\" for filename in files]))\n",
    "labels = [filename.split('/')[-1].split('_')[0] for filename in files]\n",
    "labels_set = set(labels)\n",
    "label_to_id = {label : i for i, label in enumerate(sorted(labels_set))}\n",
    "y = np.array([label_to_id[label] for label in labels])\n",
    "num_labels = len(labels_set)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_windows(x, size=mfcc_opts.frame_opts.window_size(), shift=mfcc_opts.frame_opts.window_shift()):\n",
    "#     return np.array([np.array(x[i*shift:i*shift+size]) for i in range((x.shape[0] - size) // shift)])\n",
    "# def get_windows(x, size, shift):\n",
    "#     return np.array([np.array(x[i*shift:i*shift+size]) for i in range((x.shape[0] - size) // shift)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc():\n",
    "    usage = \"\"\"Extract MFCC features.\n",
    "               Usage:  example.py [opts...] <rspec> <wspec>\n",
    "            \"\"\"\n",
    "    po = ParseOptions(usage)\n",
    "    po.register_float(\"min-duration\", 0.0,\n",
    "                      \"minimum segment duration\")\n",
    "    mfcc_opts = MfccOptions()\n",
    "    mfcc_opts.frame_opts.samp_freq = 8000\n",
    "    mfcc_opts.register(po)\n",
    "\n",
    "    opts = po.parse_args()\n",
    "    rspec, wspec = \"scp:testfile.scp\", \"ark,t:test_mfcc.ark\"\n",
    "    mfcc = Mfcc(mfcc_opts)\n",
    "    sf = mfcc_opts.frame_opts.samp_freq\n",
    "    X_mfcc = []\n",
    "#     X_raw = []\n",
    "    y = []\n",
    "    with SequentialWaveReader(rspec) as reader, \\\n",
    "             MatrixWriter(wspec) as writer:\n",
    "        for key, wav in reader:\n",
    "            if wav.duration < opts.min_duration:\n",
    "                continue\n",
    "            assert(wav.samp_freq >= sf)\n",
    "            assert(wav.samp_freq % sf == 0)\n",
    "            s = wav.data()\n",
    "            # downsample to sf [default=8kHz]\n",
    "            s = s[:,::int(wav.samp_freq / sf)]\n",
    "            # mix-down stereo to mono\n",
    "            m = SubVector(mean(s, axis=0))\n",
    "            # compute MFCC features\n",
    "            f = mfcc.compute_features(m, sf, 1.0)\n",
    "            # standardize features\n",
    "            f = SubMatrix(scale(f))\n",
    "            # write features to archive\n",
    "#             raw_windows = get_windows(m,\n",
    "#                                       size=mfcc_opts.frame_opts.window_size(),\n",
    "#                                       shift=mfcc_opts.frame_opts.window_shift())\n",
    "            f = np.array(f)\n",
    "#             f = f[:raw_windows.shape[0]]\n",
    "#             assert(f.shape[0] == raw_windows.shape[0])\n",
    "#             X_raw.append(MinMaxScaler().fit_transform(raw_windows))\n",
    "            X_mfcc.append(f)\n",
    "            answer = np.zeros(num_labels)\n",
    "            answer[label_to_id[key.split('_')[0]]] = 1.0\n",
    "            y.append(answer)\n",
    "#     return np.array(X_mfcc), np.array(X_raw), np.array(y)\n",
    "    return np.array(X_mfcc), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_mfcc, X_raw, y = get_mfcc()\n",
    "# X_mfcc, y = get_mfcc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noised_wavs_dir = \"/home/larkkin/data/noised/wav48\"\n",
    "# dirs = os.listdir(noised_wavs_dir)\n",
    "# files = []\n",
    "# for d in dirs:\n",
    "#     dir_files = os.listdir(os.path.join(noised_wavs_dir, d))\n",
    "#     files.extend([os.path.join(noised_wavs_dir, d, f) for f in dir_files if not f.startswith(\"noise\") and\\\n",
    "#                                                                             not f.endswith(\"raw\")])\n",
    "# with open(\"testfile.scp\", \"w\") as otp:\n",
    "# #     otp.write(\"TEST ../data/p225_001.wav\")\n",
    "#     otp.write('\\n'.join([f\"{filename.split('/')[-1]} {os.path.join(wavs_dir, filename)}\" for filename in files]))\n",
    "# # X_mfcc_noised, X_raw_noised, y = get_mfcc()\n",
    "# X_mfcc_noised, y = get_mfcc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"../data/mfcc.npy\", X_mfcc)\n",
    "# np.save(\"../data/mfcc_noised.npy\", X_mfcc_noised)\n",
    "X_mfcc = np.load(\"../data/mfcc.npy\")\n",
    "X_mfcc_noised = np.load(\"../data/mfcc_noised.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1\n",
    "X_mfcc_train, X_mfcc_test, X_mfcc_noised_train, X_mfcc_noised_test, y_train, y_test =\\\n",
    "    train_test_split(X_mfcc, X_mfcc_noised, y, test_size=test_size, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/mfcc_train.npy\", X_mfcc_train)\n",
    "np.save(\"../data/mfcc_test.npy\", X_mfcc_test)\n",
    "np.save(\"../data/mfcc_noised_train.npy\", X_mfcc_noised_train)\n",
    "np.save(\"../data/mfcc_noised_test.npy\", X_mfcc_noised_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/y_train.npy\", y_train)\n",
    "np.save(\"../data/y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1DTranspose(input_tensor, filters, kernel_size, strides=2, padding='same', activation='relu'):\n",
    "    x = keras.layers.Lambda(lambda x: keras.backend.expand_dims(x, axis=2))(input_tensor)\n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), strides=(strides, 1),\n",
    "                        padding=padding, activation=activation)(x)\n",
    "    x = keras.layers.Lambda(lambda x: keras.backend.squeeze(x, axis=2))(x)\n",
    "    return x\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = keras.backend.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., stddev=1.)\n",
    "    return z_mean + keras.backend.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 6\n",
    "original_dim = 13\n",
    "x_inp = Input(shape=(None, original_dim))\n",
    "x = keras.layers.GRU(latent_dim,\n",
    "                     stateful=False,\n",
    "                     return_sequences=True,\n",
    "                     go_backwards=True)(x_inp)\n",
    "z = TimeDistributed(Dense(latent_dim * 2))(x)\n",
    "x = keras.layers.GRU(original_dim,\n",
    "                     stateful=False,\n",
    "                     return_sequences=True,\n",
    "                     go_backwards=True)(z)\n",
    "x_decoded = TimeDistributed(Dense(original_dim, activation='sigmoid'))(x)\n",
    "rnn_ae = Model(x_inp, x_decoded)\n",
    "rnn_encoder = Model(x_inp, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_ae.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(X, Y):\n",
    "    for i in range(X.shape[0]):\n",
    "        x = MinMaxScaler().fit_transform(X[i])\n",
    "        x = x.reshape(1, *x.shape)\n",
    "        y = MinMaxScaler().fit_transform(Y[i])\n",
    "        y = y.reshape(1, *y.shape)\n",
    "        yield (x, y)\n",
    "def test_generator(X, k):\n",
    "    x = MinMaxScaler().fit_transform(X[k])\n",
    "    x = x.reshape(1, *x.shape)\n",
    "    yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 8s 847ms/step - loss: 0.0486\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 7s 655ms/step - loss: 0.0459\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 7s 655ms/step - loss: 0.0431\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 7s 657ms/step - loss: 0.0404\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 7s 677ms/step - loss: 0.0393\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 7s 696ms/step - loss: 0.0399\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 6s 635ms/step - loss: 0.0390\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 7s 682ms/step - loss: 0.0346\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 7s 672ms/step - loss: 0.0371\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 6s 570ms/step - loss: 0.0362\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 9s 872ms/step - loss: 0.0329\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 7s 683ms/step - loss: 0.0363\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 6s 650ms/step - loss: 0.0311\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 7s 668ms/step - loss: 0.0344\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 6s 607ms/step - loss: 0.0362\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 8s 826ms/step - loss: 0.0290\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 7s 656ms/step - loss: 0.0307\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 7s 731ms/step - loss: 0.0327\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 9s 866ms/step - loss: 0.0340\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 10s 974ms/step - loss: 0.0306\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.0309\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 6s 590ms/step - loss: 0.0337\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 6s 646ms/step - loss: 0.0302\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 7s 747ms/step - loss: 0.0302\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 7s 732ms/step - loss: 0.0295\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 7s 707ms/step - loss: 0.0332\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 7s 706ms/step - loss: 0.0273\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 8s 774ms/step - loss: 0.0302\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0289\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 7s 703ms/step - loss: 0.0317\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 7s 669ms/step - loss: 0.0335\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 8s 762ms/step - loss: 0.0291\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 7s 737ms/step - loss: 0.0311\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 8s 815ms/step - loss: 0.0260\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 7s 707ms/step - loss: 0.0334\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 7s 703ms/step - loss: 0.0328\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 7s 700ms/step - loss: 0.0318\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 7s 718ms/step - loss: 0.0317\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 8s 847ms/step - loss: 0.0276\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 6s 639ms/step - loss: 0.0327\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 8s 785ms/step - loss: 0.0305\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 0.0299\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 9s 871ms/step - loss: 0.0335\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 7s 675ms/step - loss: 0.0313\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 8s 770ms/step - loss: 0.0280\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 6s 601ms/step - loss: 0.0296\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 7s 668ms/step - loss: 0.0286\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 8s 751ms/step - loss: 0.0290\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 7s 652ms/step - loss: 0.0298\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 7s 662ms/step - loss: 0.0300\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 6s 607ms/step - loss: 0.0294\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 8s 821ms/step - loss: 0.0284\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 6s 569ms/step - loss: 0.0318\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 8s 831ms/step - loss: 0.0301\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 9s 932ms/step - loss: 0.0249\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 6s 583ms/step - loss: 0.0293\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 10s 953ms/step - loss: 0.0310\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 0.0339\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 8s 757ms/step - loss: 0.0274\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 7s 718ms/step - loss: 0.0273\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 7s 735ms/step - loss: 0.0282\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 7s 740ms/step - loss: 0.0297\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 7s 660ms/step - loss: 0.0266\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 7s 666ms/step - loss: 0.0275\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 9s 860ms/step - loss: 0.0266\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 7s 691ms/step - loss: 0.0288\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 7s 691ms/step - loss: 0.0283\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 7s 669ms/step - loss: 0.0298\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 7s 695ms/step - loss: 0.0275\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 7s 712ms/step - loss: 0.0299\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 7s 686ms/step - loss: 0.0287\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 7s 685ms/step - loss: 0.0282\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 7s 709ms/step - loss: 0.0266\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 7s 675ms/step - loss: 0.0279\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 8s 754ms/step - loss: 0.0273\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 6s 633ms/step - loss: 0.0276\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 7s 726ms/step - loss: 0.0271\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 7s 690ms/step - loss: 0.0269\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 7s 656ms/step - loss: 0.0290\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 6s 645ms/step - loss: 0.0286\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 6s 645ms/step - loss: 0.0287\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 8s 800ms/step - loss: 0.0294\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 10s 965ms/step - loss: 0.0281\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 6s 646ms/step - loss: 0.0298\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 7s 682ms/step - loss: 0.0285\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 7s 717ms/step - loss: 0.0275\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 8s 757ms/step - loss: 0.0237\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 7s 695ms/step - loss: 0.0277\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 7s 723ms/step - loss: 0.0275\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 8s 771ms/step - loss: 0.0298\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 6s 608ms/step - loss: 0.0271\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 6s 584ms/step - loss: 0.0299\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 7s 686ms/step - loss: 0.0278\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 8s 808ms/step - loss: 0.0279\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.0276\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 7s 737ms/step - loss: 0.0284\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 7s 709ms/step - loss: 0.0275\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 9s 863ms/step - loss: 0.0258\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 581ms/step - loss: 0.0266\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 7s 673ms/step - loss: 0.0271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d30be0080>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_ae.fit_generator(train_generator(X_mfcc_noised_train, X_mfcc_train),\n",
    "                     epochs=100,\n",
    "                     verbose=1,\n",
    "                     shuffle=True,\n",
    "#           validation_data=({'mfcc_input': mfcc_seq_val, 'fbank_input': fbank_seq_val},\n",
    "#                            {'main_output': y_val_seq, 'aux_output': y_val_seq}),\n",
    "#           class_weight={0 : class_weights[0], 1 : class_weights[1]},\n",
    "                     initial_epoch=0,\n",
    "                     steps_per_epoch=10,\n",
    "                     validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_k = 32735\n",
    "# pred = rnn_ae.predict_generator(test_generator(X_mfcc_noised),\n",
    "# #                      epochs=10,\n",
    "#                      verbose=1,\n",
    "#                      steps=1)\n",
    "# true = MinMaxScaler().fit_transform(X_mfcc[test_k])\n",
    "# noisy = MinMaxScaler().fit_transform(X_mfcc_noised[test_k])\n",
    "# print(((pred - true)**2).mean())\n",
    "# print(((noisy - true)**2).mean()) \n",
    "# # ((pred.reshape(*pred.shape[1:]) - X_mfcc[0])**2).mean()\n",
    "# # r1 = keras.losses.mse(pred.reshape(*pred.shape[1:]),\n",
    "# #                                  tf.convert_to_tensor(X_mfcc[0]))\n",
    "# # r2 = keras.losses.mse(tf.convert_to_tensor(X_mfcc_noised[0]),\n",
    "#                                  tf.convert_to_tensor(X_mfcc[0]))\n",
    "def predict_ae(X):\n",
    "    res = []\n",
    "    for i in range(X.shape[0]):\n",
    "        if i % 500 == 0:\n",
    "            log(f\"{i}/{X.shape[0]}\")\n",
    "        pred = rnn_ae.predict_generator(test_generator(X, i),\n",
    "                                        verbose=0,\n",
    "                                        steps=1)\n",
    "        pred = pred.reshape(*pred.shape[1:])\n",
    "        res.append(pred)\n",
    "    return res\n",
    "\n",
    "def encode(X):\n",
    "    res = []\n",
    "    for i in range(X.shape[0]):\n",
    "        if i % 500 == 0:\n",
    "            log(f\"{i}/{X.shape[0]}\")\n",
    "        pred = rnn_encoder.predict_generator(test_generator(X, i),\n",
    "                                        verbose=0,\n",
    "                                        steps=1)\n",
    "        pred = pred.reshape(*pred.shape[1:])\n",
    "        res.append(pred)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start()\n",
    "# for i, x_pred in enumerate(predict(X_mfcc_test[:201])):\n",
    "#     true = MinMaxScaler().fit_transform(X_mfcc_test[i])\n",
    "#     noised = MinMaxScaler().fit_transform(X_mfcc_noised_test[i])\n",
    "#     print(((x_pred - true)**2).mean() - ((noised - true)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_ae.save(\"./models/rnn_ae\")\n",
    "rnn_encoder.save(\"./models/rnn_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/39817, 0s, total 0s\n",
      "500/39817, 35s, total 35s\n",
      "1000/39817, 35s, total 71s\n",
      "1500/39817, 37s, total 109s\n",
      "2000/39817, 36s, total 146s\n",
      "2500/39817, 35s, total 181s\n",
      "3000/39817, 35s, total 216s\n",
      "3500/39817, 36s, total 252s\n",
      "4000/39817, 35s, total 288s\n",
      "4500/39817, 36s, total 324s\n",
      "5000/39817, 35s, total 360s\n",
      "5500/39817, 35s, total 395s\n",
      "6000/39817, 36s, total 431s\n",
      "6500/39817, 35s, total 466s\n",
      "7000/39817, 36s, total 502s\n",
      "7500/39817, 36s, total 538s\n",
      "8000/39817, 35s, total 574s\n",
      "8500/39817, 37s, total 611s\n",
      "9000/39817, 36s, total 647s\n",
      "9500/39817, 35s, total 683s\n",
      "10000/39817, 37s, total 720s\n",
      "10500/39817, 36s, total 756s\n",
      "11000/39817, 35s, total 792s\n",
      "11500/39817, 36s, total 829s\n",
      "12000/39817, 36s, total 865s\n",
      "12500/39817, 35s, total 900s\n",
      "13000/39817, 36s, total 936s\n",
      "13500/39817, 34s, total 971s\n",
      "14000/39817, 36s, total 1008s\n",
      "14500/39817, 34s, total 1042s\n",
      "15000/39817, 37s, total 1080s\n",
      "15500/39817, 35s, total 1115s\n",
      "16000/39817, 35s, total 1150s\n",
      "16500/39817, 35s, total 1186s\n",
      "17000/39817, 36s, total 1222s\n",
      "17500/39817, 35s, total 1258s\n",
      "18000/39817, 35s, total 1294s\n",
      "18500/39817, 35s, total 1329s\n",
      "19000/39817, 34s, total 1364s\n",
      "19500/39817, 35s, total 1400s\n",
      "20000/39817, 35s, total 1435s\n",
      "20500/39817, 34s, total 1470s\n",
      "21000/39817, 36s, total 1507s\n",
      "21500/39817, 35s, total 1543s\n",
      "22000/39817, 35s, total 1578s\n",
      "22500/39817, 35s, total 1614s\n",
      "23000/39817, 35s, total 1649s\n",
      "23500/39817, 35s, total 1685s\n",
      "24000/39817, 36s, total 1721s\n",
      "24500/39817, 35s, total 1757s\n",
      "25000/39817, 36s, total 1793s\n",
      "25500/39817, 35s, total 1828s\n",
      "26000/39817, 35s, total 1864s\n",
      "26500/39817, 35s, total 1900s\n",
      "27000/39817, 35s, total 1936s\n",
      "27500/39817, 36s, total 1972s\n",
      "28000/39817, 34s, total 2007s\n",
      "28500/39817, 36s, total 2043s\n",
      "29000/39817, 36s, total 2079s\n",
      "29500/39817, 35s, total 2115s\n",
      "30000/39817, 35s, total 2151s\n",
      "30500/39817, 35s, total 2187s\n",
      "31000/39817, 36s, total 2223s\n",
      "31500/39817, 35s, total 2259s\n",
      "32000/39817, 34s, total 2293s\n",
      "32500/39817, 34s, total 2328s\n",
      "33000/39817, 35s, total 2364s\n",
      "33500/39817, 35s, total 2400s\n",
      "34000/39817, 35s, total 2436s\n",
      "34500/39817, 35s, total 2471s\n",
      "35000/39817, 35s, total 2507s\n",
      "35500/39817, 37s, total 2544s\n",
      "36000/39817, 34s, total 2579s\n",
      "36500/39817, 34s, total 2614s\n",
      "37000/39817, 34s, total 2649s\n",
      "37500/39817, 36s, total 2685s\n",
      "38000/39817, 35s, total 2721s\n",
      "38500/39817, 35s, total 2756s\n",
      "39000/39817, 36s, total 2793s\n",
      "39500/39817, 36s, total 2830s\n"
     ]
    }
   ],
   "source": [
    "start()\n",
    "ae_features_train = np.array(encode(X_mfcc_noised_train))\n",
    "np.save(arr=ae_features_train, file=\"../data/ae_features_noised_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/4425, 0s, total 0s\n",
      "500/4425, 35s, total 35s\n",
      "1000/4425, 35s, total 71s\n",
      "1500/4425, 33s, total 105s\n",
      "2000/4425, 36s, total 141s\n",
      "2500/4425, 35s, total 177s\n",
      "3000/4425, 35s, total 212s\n",
      "3500/4425, 35s, total 247s\n",
      "4000/4425, 34s, total 282s\n"
     ]
    }
   ],
   "source": [
    "start()\n",
    "ae_features_test = np.array(encode(X_mfcc_noised_test))\n",
    "np.save(arr=ae_features_test, file=\"../data/ae_features_noised_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps` or use the `keras.utils.Sequence` class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-46d653b0d502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn_ae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_mfcc_noised\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/main_env/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/main_env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             verbose=verbose)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/main_env/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             raise ValueError('`steps=None` is only valid for a generator'\n\u001b[0m\u001b[1;32m    407\u001b[0m                              \u001b[0;34m' based on the `keras.utils.Sequence` class.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                              \u001b[0;34m' Please specify `steps` or use the'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps` or use the `keras.utils.Sequence` class."
     ]
    }
   ],
   "source": [
    "rnn_ae.predict_generator(test_generator(X_mfcc_noised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mfcc_input = Input(shape=(None, 13), name='mfcc_input')\n",
    "gru1 = keras.layers.GRU(64,\n",
    "                        stateful=False,\n",
    "                        return_sequences=True)(mfcc_input)\n",
    "aux_output = Dense(num_labels, activation='softmax', name='aux_output')(gru1)\n",
    "\n",
    "raw_input = Input(shape=(None, 200), name='raw_input')\n",
    "gru2 = keras.layers.GRU(20,\n",
    "                        stateful=False,\n",
    "                        return_sequences=True)(raw_input)\n",
    "\n",
    "x = keras.layers.concatenate([gru1, gru2])\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "main_output = Dense(num_labels, activation='softmax', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[mfcc_input, raw_input], outputs=[main_output, aux_output])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(X_mfcc, X_raw, y):\n",
    "    for i in range(X_mfcc.shape[0]):\n",
    "        mfcc = X_mfcc[i]\n",
    "        raw = X_raw[i]\n",
    "        local_y = np.array([y[i]] * mfcc.shape[0]).reshape(1, mfcc.shape[0], num_labels)\n",
    "        yield ({'mfcc_input': mfcc.reshape(1, *mfcc.shape),\n",
    "                'raw_input': raw.reshape(1, *raw.shape)},\n",
    "               {'main_output': local_y, 'aux_output': local_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-14702836ca78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5435\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_mfcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m model.fit_generator(train_generator(X_mfcc, X_raw, y),\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_raw' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(X_mfcc), len(X_raw), y.shape)\n",
    "model.fit_generator(train_generator(X_mfcc, X_raw, y),\n",
    "          epochs=3,\n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "#           validation_data=({'mfcc_input': mfcc_seq_val, 'fbank_input': fbank_seq_val},\n",
    "#                            {'main_output': y_val_seq, 'aux_output': y_val_seq}),\n",
    "#           class_weight={0 : class_weights[0], 1 : class_weights[1]},\n",
    "          initial_epoch=0,\n",
    "          steps_per_epoch=10,\n",
    "          validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "i = 0\n",
    "answers = []\n",
    "for inp, otp in train_generator(X_mfcc, X_raw, y):\n",
    "    i += 1\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    current_res = model.predict(inp)\n",
    "    predictions.append(current_res)\n",
    "    answers.append(otp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0][0].reshape(-1, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "corrects = 0\n",
    "for i in range(len(answers)):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    a = answers[i]['main_output'].reshape(-1, 2)\n",
    "    p = predictions[i][0].reshape(-1, 2)\n",
    "    counter += a.shape[0]\n",
    "    corrects += (np.argmax(p, axis=1) == np.argmax(a, axis=1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.614907053347938"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252887"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(x, size=mfcc_opts.frame_opts.window_size(), shift=mfcc_opts.frame_opts.window_shift()):\n",
    "    return np.array([np.array(x[i*shift:i*shift+size]) for i in range((x.shape[0] - size) // shift)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinary_windows = get_windows(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = X_mfcc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 231, (231,))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 13)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 200)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinary_windows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(612, 13)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mfcc[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = 200\n",
    "intermediate_dim = 40\n",
    "latent_dim = 13\n",
    "batch_size = 15\n",
    "stride=1\n",
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)\n",
    "\n",
    "z = keras.layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "# end-to-end autoencoder\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model(x, z_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-1099df008245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mz_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mz_log_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_log_sigma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sampling' is not defined"
     ]
    }
   ],
   "source": [
    "original_dim = 200\n",
    "latent_dim = 12\n",
    "batch_size = 15\n",
    "stride=2\n",
    "x_inp = Input(batch_shape=(batch_size, original_dim))\n",
    "x = Reshape((original_dim, 1))(x_inp)\n",
    "x = Conv1D(64,3, activation='relu', padding='valid', strides=stride)(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Conv1D(32,3, activation='relu', padding='valid', strides=stride)(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "h = Flatten()(x)\n",
    "\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)\n",
    "z = keras.layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "x = Reshape((latent_dim, 1))(z)\n",
    "x = Conv1DTranspose(x, 32, 3, activation='relu', padding='valid', strides=stride)\n",
    "x = UpSampling1D(2)(x)\n",
    "x = Conv1DTranspose(x, 64, 3, activation='relu', padding='valid', strides=stride)\n",
    "x = UpSampling1D(2)(x)\n",
    "x = Flatten()(x)\n",
    "x_decoded = Dense(original_dim,activation = 'sigmoid')(x)\n",
    "vae = Model(x_inp, x_decoded)\n",
    "encoder = Model(x_inp, z_mean)\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    l = 5.01\n",
    "    xent_loss = keras.losses.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - l * keras.backend.mean(1 + z_log_sigma - keras.backend.square(z_mean) - \\\n",
    "                                     keras.backend.exp(z_log_sigma),\n",
    "                                 axis=-1)\n",
    "    return xent_loss + kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='rmsprop', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(plain_raw_features,\n",
    "        plain_raw_features,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        shuffle=True,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(612, 200)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_raw_features.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/larkkin/miniconda3/envs/main_env/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.54919334, -1.161895  , -0.77459667, -0.38729833,  0.        ,\n",
       "        0.38729833,  0.77459667,  1.161895  ,  1.54919334])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale(np.arange(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
